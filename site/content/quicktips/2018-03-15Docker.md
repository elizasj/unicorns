+++
date = "2018-03-15T00:00:00Z"
tags = ["quicktips", "tooling", "DNS", "containers"]
title = "Docker"
draft = false
type = "quicktips"
+++

Containers are not a new idea in the programing world, but when I first encountered <a href="https://www.google.fr/search?q=docker&ie=utf-8&oe=utf-8&client=firefox-b-ab&gfe_rd=cr&dcr=0&ei=pYytWvXgFvGZX6LjsbgN" target="_blank">Docker</a>, which essentially _containerizes all the things_, I have to admit I was pretty overwhelemed. It's a universe unto itself, and there’s definitely a bit of a learning curve when it comes to getting your bearings with this tool/set of tools (because there's Docker, and then all the different parts of Docker and how they all work together...)  

## Some vocabulary
- - images
- - containers
- - volumes
- - servers
- - ports 

## Some Context
My first steps using <a href="https://www.docker.com" target="_blank">Docker</a> had me feeling like I was writing something similar to the <a href=“https://en.wikipedia.org/wiki/Pseudocode” target="_blank">pseudo code</a> I sometimes use to hash out ideas. Wich is kind of cool because that means it felt familiar, inviting, unintimidating even. But pseudo code can also kind of feel abstract if you're not sure what's happening under the hood. I quickly realised that I needed a refresher in all things networking to really be able to use Docker to it’s full potential. This is especially true if you’re using Docker on a Mac.

Docker plays most friendly with Linux systems because it was conceived for linux systems first and foremost, and requires a virtual machine (vm) to run on a Mac (which feels pretty ironic conisdering once of the main arguments for Docker being so great is that it's so much lighter and faster than a vm... but anyways...) So when you install <a href="https://docs.docker.com/docker-for-mac/" target="_blank">docker-for-mac</a> on your system keep in mind that any `ports` you expose in your `Dockerfile` will have to be mapped to ports outside the vm in order to render anything into the browser. Hold on to that thought, because we’ll come back to it in a minute.

### Images

`Images` are snapshots of programs. For example, if you have a development environment all set up, and you want to turn it into an image, you’d create a Dockerfile just outside your project directory and fill it with everything your project needs to run.

Here is an example of an image I created for a locally hosted <a href="https://www.gatsbyjs.org" target="_blank">Gatsbyjs</a> project:

```JSON
//Dockerfile
#build
FROM node:9
WORKDIR /var/www/html
COPY entrypoint.sh /entrypoint.sh
RUN npm install --global gatsby-cli
EXPOSE 8888
ENV CHOKIDAR_USEPOLLING=true CHOKIDAR_INTERVAL=1
#run
CMD /entrypoint.sh
```
- - __FROM__ indicates what image of Node I'm relying on to run my project (an image I had installed from <a href="https://hub.docker.com/" target="_blank">docker-hub</a>.)
- - __WORKDIR__ here I specify where on the server to point the locally hosted project files when the container is running
- - __COPY__ grabs a file (in this case a bash file, `entrypoint.sh`, and copies it's contents to a new file (in this case a file of the same name)
- - __RUN__ does what you'd expect, aka run a command as if in the terminal
- - __EXPOSE__ exposes the port of your choice
- - __ENV__ is where you can define any environement variables needed 
- - __CMD__  runs the final comand to get everything going. (In this case the final comand reaches into the `entrypoint.sh` and boots up the Gatsbyjs project)

```Bash
//entrypoint.sh
#! /bin/bash
yarn
gatsby develop --host 0.0.0.0 --port 8888
```
#### N.B. - This image is for a development workflow, so I created a bash file to be able to run yarn dynamically when I start up my docker container. This is so that Gatsby doesn’t run until all the files are on the file system via the bind mount, which I'll explain in a second. But just keep in mind that when the image is production ready, this step wouldn't be needed. 

### Containers:

A `container` is an instance of an `image` that you can then modify/config to your personal needs. You generally have one service per container - a simple example would be your web service, your backoffice cms, and your database. Each has their own container and if you stop a container, you kill your instance and any data you were using within it is wiped out.

Above I showed you how to create an `image` based on local project files. In my `Dockerfile`, I had to specify an entry point in a bash file, which runs the commands to boot up the project from the local folder. Since it’s a working development environment, I want to be able to modify my files and see the changes rendered in the browser.

### Volumes

Enter `volumes`, which are directories specifically designed to allow your changes to be taken into account by the container (or say, if you needed some data to persist through any future containers you might start/stop, but we’ll come back to this…) 

There are two types of volumes - bind mounts, Docker's anonymous volumes, and named mounts, Docker volumes that you create manually and assign yourself. In the case of my Gatsby project, we'll use a bind mount to run things from the command line.

## Piecing it all together:

#### 1. Build your docker image

```javascript
docker build -t gatsbylocal .
```
- - `-t` is a tag flag that your giving to your image, which is helpful when you’re in the terminal figuring out what’s happening
- - the `.` means build from the current directory. Your location in the terminal when you run this command is important.

#### 2. Run your docker container and use a volume to siphon in the files from your locally stored project, to the server

```javascript
docker run -d --name gatsbystory -p 8888:8888  -v $(pwd)/gatsby:/var/www/html  gatsbylocal  
```

- - `-d` is a tag that gets things running in the background so you can still work in your terminal
- - We're `--name`-ing the container __gatsbystory__ 
- - The `-p` tag maps the `port` defined on the right to the one on the left, which kind of feels backwards, right? But __HOST_PORT:CONTAINER_PORT__. In this case they're both the same but IRL you can change the port on the left to whatever you want. The command basically makes whatever is running on __port 8888__ (the port that u exposed in your initial Docker image, remember) accessible by __localhost:8888__ in the browser. On a linux machine you wouldn’t need to explicitly tell docker where to look. This is entirely because of how Docker works from within a vm on a Mac.
- - `-v` attaches an anonymous `volume` to your local project folder (in this case, __gatsby__) and sends any changes made to that folder to the destination path on the server being run in your docker instance... well, sort of. Actually, from the pov of the kernel,  the bind mount is the same bunch of files - so it's sort of like being in <a hre="https://www.youtube.com/watch?v=OMlYpH1lOYg">two places at once</a>. (Yes I did just make that reference. #2000s)

When you run this command, you'll have a working instance, and thanks to the volume you set up, any changes you make while developing will be taken into account directly in the browser. Great! 

But if each service goes into a seperate container... how do you make containers work together? How would I hook up my Gatsbyjs project to a backoffice cms, which needs a database.

## Docker-compose

Docker really clicked for me when I started using <a href="https://docs.docker.com/compose/overview/" target="_blank">docker-compose</a>, which feels like a Dockerfile that sits on top of a bunch of Dockerfiles (or rather, the images they describe...) telling them how to play nice with each other. (The more technical way of saying this would be that Docker runs at build time, whereas Docker-compose runs at run time.) 
In our case the local Gatsby project already has it's image. Instead of writing two more images, I'm going to pull some pre-made ones from <a href="https://hub.docker.com/" target="_blank">docker hub</a> for the cms and database I want to hook up to my project. (__Hint:__ official project images > random user uploaded images, as they are most trustworthy.) 

We could tediously run each image from the terminal using commands similar to the one outlined above, but docker-compose exists so that we don't have to. Instead we can create a `docker-compose.yml` file in the same place as your initial Gatsbyjs Docker file, to get things running from a single source. All that's left to do after that is run 

```JSON
docker-compose up
```
from your terminal to boot everything up. Sounds simple enough but there are some networking and environment variable things that you need to take into account.

In this example we’ll be hooking up an image of a gatsby project, with a cms called <a href="https://hub.docker.com/r/agentejo/cockpit/" target="_blank">cockpit</a>, which relies on <a href="https://hub.docker.com/_/mongo/" target="_blank">mongodb</a>. So three images are going to be linked together.

First thing, set your `version` of docker compose (I'm using __v 3__)

```javascript
//docker-compose.yml
version: '3'
```
Next, list out the various `services` that you’ll be using. Services are run via images. So each service runs an image that creates a container. I named them `db`, `cms` and `web` but you can call your services whatever you want. Since my Gatsbyjs project is running from a local development image, and our docker-compose.yml file is in the same location, I include `build .` instead of pointing to a pre-made image.
Don't forget to define the ports you want to map so things load properly in the browser. 

__N.B since we aren't accessing the datbase directly, but instead via our cms, that particular port with be set later on, using cockpits environment varialbes.__ 

```javascript
//docker-compose.yml
version: '3'
services:
  db:
    image: 'mongo'
  cms:
    image: 'aheinze/cockpit'
    ports:
      - "8080:80"
  web:
    build: .
    ports:
      - "8888:8888"
```

Add a network (or `networks`, which is why the heading must always be plural. In our case we need just one.) Again, you can call your network whatever you want.

Inside your network, set a `bridge` (which does what you might expect… bridges things together over the network you just defined) you can create a bridge or use the default that comes built in. Each has it’s merits but for our purposes we only need the default. Read up on the differences <a href=“https://docs.docker.com/network/bridge/“ target="_blank">here</a>

```javascript
//docker-compose.yml
version: '3'
services:
  db:
    image: 'mongo'
  cms:
    image: 'aheinze/cockpit'
    ports:
      - "8080:80"
  web:
    build: .
    ports:
      - "8888:8888"
networks:
  banana:
    driver: bridge
```

Now define a volume (or `volumes`, - which is why the heading must always be plural. In our case we need just one.) In the initial image created above, we used an anonymous volume that Docker created for us. But you can also define your own volume, which is handy in this case, since it’ll contain the data we’ll want to serve out to the __mongodb container__ every time we boot up the system. In your terminal: 

```JSON
docker volume create --name whatever-you-want-to-name-your-volume
```

Double check to see it’s been created,

```JSON
volume list
```

then add it to your `docker-compose.yml`

```javascript
//docker-compose.yml
version: '3'
services:
  db:
    image: 'mongo'
  cms:
    image: 'aheinze/cockpit'
    ports:
      - "8080:80"
  web:
    build: .
    ports:
      - "8888:8888"
networks:
  banana:
    driver: bridge
volumes:
  mongo-vol: null
```

Within each service (__db__, __cms__, __web__) add the network they will be communicating through.

```javascript
//docker-compose.yml
version: '3'
services:
  db:
    image: 'mongo'
    networks:
      - banana
  cms:
    image: 'aheinze/cockpit'
    ports:
      - "8080:80"
    networks:
      - banana
  web:
    build: .
    ports:
      - "8888:8888"
    networks:
      - banana
networks:
  banana:
    driver: bridge
volumes:
  mongo-vol: null
```

In your __db service__, connect the volume you created to the database path (this set up info is usually explained on docker hub, so it can be different if you’re using a different image, but this is how it works with Cockpit.)

```javascript
//docker-compose.yml
version: '3'
services:
  db:
    image: 'mongo'
    volumes:
      - 'mongo-vol:/data/db'
    networks:
      - banana
  cms:
    image: 'aheinze/cockpit'
    ports:
      - "8080:80"
    networks:
      - banana
  web:
    build: .
    ports:
      - "8888:8888"
    networks:
      - banana
networks:
  banana:
    driver: bridge
volumes:
  mongo-vol: null
```

Netxt, configure the environment variables of the service that is dependant on the database (our cms, cockpit) and point it to the database (again, these details should be specified on docker hub or in the docs… in the case of cockpit, a bit of digging needed to be done. Hat tip to <a href="https://twitter.com/_superseed" target="_blank">@superspeed</a>, who helped me find this info, and who also repeatedly hashed out Docker's more confusing parts with me 🙏🙏.) As mentioned earlier, this is where you'll the cms to the database server, in this case the __COCKPIT_DATABASE_SERVER__

```javascript
//docker-compose.yml
version: '3'
services:
  db:
    image: 'mongo'
    volumes:
      - 'mongo-vol:/data/db'
    networks:
      - banana
  cms:
    image: 'aheinze/cockpit'
    ports:
      - "8080:80"
    environment:
      COCKPIT_SESSION_NAME: cockpit
      COCKPIT_SALT: //create-your-own//
      COCKPIT_DATABASE_SERVER: 'mongodb://db:27017'
      COCKPIT_DATABASE_NAME: cockpit_master
    depends_on:
      - db
    networks:
      - banana
  web:
    build: .
    ports:
      - "8888:8888"
    networks:
      - banana
networks:
  banana:
    driver: bridge
volumes:
  mongo-vol: null
```

__Tip:__ Send your .yml file through a linter and save yourself some weird error messages. Once you're cleared, you're good to go! Run 

```JSON
docker-compose up
```

#### Some handy docker command line stuff :

- - __Docker image ls -a__ (see all your images)
- - __Docker container ls -a__ (see all your containers)
- - __Docker container stop__
- - __Docker container rm__ (remove a container)
- - __Docker container rm -f__ (force the removal of a container)
- - __Docker image rmi__ (container must be stoped to kill an image)
- - __Docker container prune__ (get rid of unused containers)
- - __Docker image prune__ (get rid of unused images)
- - __Docker volume prune__ (get rid of unused volumes)
- - __Docker volume list__ (list out volumes)

#### Exposing ports
As I said above, on a mac, Docker needs to reach outside it's vm so that when your containers run their various servers, the urls can be redirected to the exposed ports. Here's how it works under the hood on a mac, and how the VM on your mac works with Docker.

##### Docker for Mac
<img src="/images/DockerMac.png">

#### Linux Virtual Machine
<img src="/images/DockerLinux.png">

Containers can be represented as boxes that interface with the 'outside' via ports. These interfaces each have IP addresses, and the containers open ports for the apps inside to access the outside. Containers can be bridged together, and the docker daemon maps those open container ports to the outside world, the 'real ports' illustrated in the first diagram. This makes the containers accessible through localhost (or the host’s IP address) instead of just the container IP/port.